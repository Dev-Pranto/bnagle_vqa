{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13558499,"sourceType":"datasetVersion","datasetId":8612141},{"sourceId":13594972,"sourceType":"datasetVersion","datasetId":8638178}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Update transformers\n!pip install --upgrade transformers\n!pip install git+https://github.com/huggingface/transformers.git\n# First, let's install a specific version\n!pip install -q -U \"transformers>=4.42.0\" accelerate bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T09:49:00.261654Z","iopub.execute_input":"2025-12-07T09:49:00.261908Z","iopub.status.idle":"2025-12-07T09:51:01.908664Z","shell.execute_reply.started":"2025-12-07T09:49:00.261887Z","shell.execute_reply":"2025-12-07T09:51:01.907750Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nCollecting transformers\n  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\nSuccessfully installed tokenizers-0.22.1 transformers-4.57.3\nCollecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-8fd5sof1\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-8fd5sof1\n  Resolved https://github.com/huggingface/transformers.git to commit ff13eb668aa03f151ded71636d723f2e490ad967\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (3.20.0)\nCollecting huggingface-hub<2.0,>=1.0.0 (from transformers==5.0.0.dev0)\n  Downloading huggingface_hub-1.2.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (0.22.1)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (0.20.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.2.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (0.28.1)\nRequirement already satisfied: shellingham in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.5.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (4.15.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (2025.10.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (0.16.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==5.0.0.dev0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.3.1)\nDownloading huggingface_hub-1.2.1-py3-none-any.whl (520 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.9/520.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=10887812 sha256=1ce8c91fdc021c809a5607241f325f25c6c912cd88c5a6aa3af3b75894ee2051\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3qsizlba/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\nSuccessfully built transformers\nInstalling collected packages: huggingface-hub, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.36.0\n    Uninstalling huggingface-hub-0.36.0:\n      Successfully uninstalled huggingface-hub-0.36.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.3\n    Uninstalling transformers-4.57.3:\n      Successfully uninstalled transformers-4.57.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-1.2.1 transformers-5.0.0.dev0\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torch torchvision\n!pip install qwen-vl-utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T09:51:01.910448Z","iopub.execute_input":"2025-12-07T09:51:01.910797Z","iopub.status.idle":"2025-12-07T09:51:13.651229Z","shell.execute_reply.started":"2025-12-07T09:51:01.910766Z","shell.execute_reply":"2025-12-07T09:51:13.650500Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nCollecting qwen-vl-utils\n  Downloading qwen_vl_utils-0.0.14-py3-none-any.whl.metadata (9.0 kB)\nCollecting av (from qwen-vl-utils)\n  Downloading av-16.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from qwen-vl-utils) (25.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from qwen-vl-utils) (11.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from qwen-vl-utils) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->qwen-vl-utils) (2025.10.5)\nDownloading qwen_vl_utils-0.0.14-py3-none-any.whl (8.1 kB)\nDownloading av-16.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (40.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av, qwen-vl-utils\nSuccessfully installed av-16.0.1 qwen-vl-utils-0.0.14\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport json\nfrom PIL import Image\n\n# Define all file paths\nBANGLA_QUESTIONS_PATH = \"/kaggle/input/test-nlp/Bangla_Train_Ques_220K.json\"\nBANGLA_ANSWERS_PATH = \"/kaggle/input/test-nlp/Bangla_Train_Ans_220K.json\"\nIMAGE_DIR = \"/kaggle/input/nlp-image/train2014\"\n\nprint(\"Loading data files...\")\n\n# Load Bangla questions and answers\nwith open(BANGLA_QUESTIONS_PATH, 'r', encoding='utf-8') as f:\n    bangla_questions = json.load(f)\n\nwith open(BANGLA_ANSWERS_PATH, 'r', encoding='utf-8') as f:\n    bangla_answers = json.load(f)\n\nprint(f\"Loaded {len(bangla_questions)} questions and {len(bangla_answers)} answers\")\n\n# Create mapping from question_id to answer\nquestion_id_to_answer = {}\nfor answer in bangla_answers:\n    question_id_to_answer[answer['question_id']] = answer['multiple_choice_answer']\n\nprint(f\"Created answer mapping for {len(question_id_to_answer)} questions\")\n\n# Get all available image files\nprint(f\"\\nScanning image directory: {IMAGE_DIR}\")\nimage_files = os.listdir(IMAGE_DIR)\nprint(f\"Found {len(image_files)} images in train2014 directory\")\n\n# Create a mapping from image_id to filename by extracting IDs from filenames\nimage_id_to_filename = {}\nfor filename in image_files:\n    if filename.endswith('.jpg'):\n        parts = filename.split('_')\n        if len(parts) >= 3:\n            image_id_str = parts[-1].replace('.jpg', '')\n            try:\n                image_id = int(image_id_str)\n                image_id_to_filename[image_id] = filename\n            except ValueError:\n                continue\n\nprint(f\"Created image ID mapping for {len(image_id_to_filename)} images\")\n\n# --- MODIFIED SECTION ---\n\n# Create test data\nprint(\"\\nCreating test data... (This may take a while)\")\ntest_data = []\nsuccessful_samples = 0\nfailed_samples = 0\nfailed_alternative_samples = 0\n\n# Use enumerate for progress tracking\n# REMOVED the [:50] slice to process ALL questions\nfor i, question in enumerate(bangla_questions): \n    image_id = question['image_id']\n    question_id = question['question_id']\n    question_text = question['question']\n    \n    # Get the answer\n    answer = question_id_to_answer.get(question_id, \"Unknown\")\n    \n    # Get the image filename\n    image_filename = image_id_to_filename.get(image_id)\n    \n    image_path = None\n    \n    if image_filename:\n        # Primary check\n        image_path = os.path.join(IMAGE_DIR, image_filename)\n        if not os.path.exists(image_path):\n            # Only print the first 5 errors to avoid spam\n            if failed_samples < 5:\n                print(f\"Image path doesn't exist: {image_path}\")\n            failed_samples += 1\n            image_path = None # Reset path\n            \n    else:\n        # Try alternative: search for any image with this ID pattern\n        search_id = f\"{image_id:012d}\"\n        found_alternative = None\n        for filename in image_files:\n            if search_id in filename:\n                found_alternative = filename\n                break\n        \n        if found_alternative:\n            image_path = os.path.join(IMAGE_DIR, found_alternative)\n        else:\n            # Only print the first 5 errors to avoid spam\n            if failed_alternative_samples < 5:\n                 print(f\"Failed to find any image for ID {image_id} (search key: {search_id})\")\n            failed_alternative_samples += 1\n\n    # If we successfully found an image path (either way)\n    if image_path:\n        sample = {\n            \"id\": f\"bangla_vqa_{question_id}\",\n            \"image\": image_path, # Use the verified path\n            \"conversations\": [\n                {\n                    \"from\": \"human\",\n                    \"value\": f\"<image>\\n{question_text}\"\n                },\n                {\n                    \"from\": \"gpt\", \n                    \"value\": answer\n                }\n            ]\n        }\n        test_data.append(sample)\n        successful_samples += 1\n    \n    # --- Progress Tracker ---\n    if (i + 1) % 10000 == 0:\n        print(f\"  ... Processed {i + 1} / {len(bangla_questions)} questions\")\n\n# --- END OF MODIFIED SECTION ---\n\nprint(f\"\\nSuccessfully created {successful_samples} test samples\")\nprint(f\"Failed (path invalid): {failed_samples} samples\")\nprint(f\"Failed (no image found): {failed_alternative_samples} samples\")\n\n# Save the test data\nif test_data:\n    output_filename = 'bangla_vqa_train_full.json'\n    with open(output_filename, 'w', encoding='utf-8') as f:\n        json.dump(test_data, f, ensure_ascii=False, indent=2)\n    print(f\"Full training data saved as '{output_filename}'\")\n\n    # Show sample of created data\n    print(\"\\nSample created test data:\")\n    for i, sample in enumerate(test_data[:3]):\n        question_text = sample['conversations'][0]['value'].replace('<image>\\n', '')\n        print(f\"\\nSample {i+1}:\")\n        print(f\"  Image: {os.path.basename(sample['image'])}\")\n        print(f\"  Question: {question_text}\")\n        print(f\"  Answer: {sample['conversations'][1]['value']}\")\nelse:\n    print(\"ERROR: No test data was created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T09:51:13.652290Z","iopub.execute_input":"2025-12-07T09:51:13.652547Z","iopub.status.idle":"2025-12-07T09:57:04.410220Z","shell.execute_reply.started":"2025-12-07T09:51:13.652522Z","shell.execute_reply":"2025-12-07T09:57:04.409560Z"}},"outputs":[{"name":"stdout","text":"Loading data files...\nLoaded 220000 questions and 220000 answers\nCreated answer mapping for 220000 questions\n\nScanning image directory: /kaggle/input/nlp-image/train2014\nFound 69933 images in train2014 directory\nCreated image ID mapping for 69933 images\n\nCreating test data... (This may take a while)\nFailed to find any image for ID 524291 (search key: 000000524291)\nFailed to find any image for ID 524291 (search key: 000000524291)\nFailed to find any image for ID 524291 (search key: 000000524291)\nFailed to find any image for ID 393224 (search key: 000000393224)\nFailed to find any image for ID 393224 (search key: 000000393224)\n  ... Processed 10000 / 220000 questions\n  ... Processed 20000 / 220000 questions\n  ... Processed 30000 / 220000 questions\n  ... Processed 40000 / 220000 questions\n  ... Processed 50000 / 220000 questions\n  ... Processed 60000 / 220000 questions\n  ... Processed 70000 / 220000 questions\n  ... Processed 80000 / 220000 questions\n  ... Processed 90000 / 220000 questions\n  ... Processed 100000 / 220000 questions\n  ... Processed 110000 / 220000 questions\n  ... Processed 120000 / 220000 questions\n  ... Processed 130000 / 220000 questions\n  ... Processed 140000 / 220000 questions\n  ... Processed 150000 / 220000 questions\n  ... Processed 160000 / 220000 questions\n  ... Processed 170000 / 220000 questions\n  ... Processed 180000 / 220000 questions\n  ... Processed 190000 / 220000 questions\n  ... Processed 200000 / 220000 questions\n  ... Processed 210000 / 220000 questions\n  ... Processed 220000 / 220000 questions\n\nSuccessfully created 185465 test samples\nFailed (path invalid): 0 samples\nFailed (no image found): 34535 samples\nFull training data saved as 'bangla_vqa_train_full.json'\n\nSample created test data:\n\nSample 1:\n  Image: COCO_train2014_000000458752.jpg\n  Question: এই ছবিটি কিসের মাধ্যমে তোলা হয়েছে?\n  Answer: নেট\n\nSample 2:\n  Image: COCO_train2014_000000458752.jpg\n  Question: এই লোকটি কোন অবস্থানে খেলছে?\n  Answer: কলস\n\nSample 3:\n  Image: COCO_train2014_000000458752.jpg\n  Question: খেলোয়াড়দের শার্টের রং কি?\n  Answer: কমলা\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install fuzzywuzzy[levenshtein]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T09:57:04.410915Z","iopub.execute_input":"2025-12-07T09:57:04.411174Z","iopub.status.idle":"2025-12-07T09:57:07.532519Z","shell.execute_reply.started":"2025-12-07T09:57:04.411153Z","shell.execute_reply":"2025-12-07T09:57:07.531625Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: fuzzywuzzy[levenshtein] in /usr/local/lib/python3.11/dist-packages (0.18.0)\n\u001b[33mWARNING: fuzzywuzzy 0.18.0 does not provide the extra 'levenshtein'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport sys\nimport os\nimport json\nimport base64\nimport csv\nfrom io import BytesIO\nfrom PIL import Image\nimport transformers\nfrom fuzzywuzzy import fuzz\nfrom IPython.display import display, HTML, Image as IPImage\n\n# --- [STEP 1/2] Load Model and Processor ---\nprint(f\"--- Loading Model and Processor... ---\")\nprint(f\"Using transformers version: {transformers.__version__}\")\n\ntry:\n    from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n    print(\"✓ Successfully imported Qwen2VLForConditionalGeneration\")\nexcept ImportError as e:\n    print(f\"FATAL: Could not import Qwen2VL. Did you restart the runtime?\")\n    print(f\"Error: {e}\")\n    sys.exit(1)\n\n# Model configuration\nmodel_id = \"Qwen/Qwen2-VL-7B-Instruct\"\ntest_file = \"bangla_vqa_train_full.json\" # Ensure path matches your output from Part 1\nN_SAMPLES = 150\nN_PRINT_SAMPLES = 10  # Only print details for the first 10\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Using device: {device}\")\n\nif not os.path.exists(test_file):\n    print(f\"FATAL ERROR: File not found: {test_file}\")\n    # In a notebook, we might not want to exit strictly, but here it's safer\n    # sys.exit() \n\n# Load processor\nprint(\"Loading processor...\")\nprocessor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\nprint(\"✓ Processor loaded successfully\")\n\n# Load model\nprint(\"Loading model...\")\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    trust_remote_code=True,\n    device_map=\"auto\"\n)\nprint(\"✓ Model loaded successfully.\")\n\n# --- [STEP 2/2] Load Test Data and Run Inference ---\nprint(f\"\\n--- Loading test data and running inference... ---\")\nwith open(test_file, 'r', encoding='utf-8') as f:\n    test_data = json.load(f)\n\nN_SAMPLES = min(N_SAMPLES, len(test_data))\ntest_samples = test_data[:N_SAMPLES]\nprint(f\"Running inference on {len(test_samples)} Bangla VQA samples...\")\n\ncorrect_predictions = 0\ntotal_similarity_score = 0\nresults = []\n\nfor i, sample in enumerate(test_samples):\n    try:\n        image_path = sample['image']\n        question = sample['conversations'][0]['value'].replace('<image>\\n', '').strip()\n        ground_truth_answer = sample['conversations'][1]['value']\n        \n        if not os.path.exists(image_path):\n            print(f\"SKIPPING: Image not found at {image_path}\")\n            continue\n            \n        image = Image.open(image_path).convert(\"RGB\")\n        \n        # Bangla Prompt\n        bangla_prompt = f\"\"\"ছবির উপর ভিত্তি করে এই প্রশ্নের উত্তর দিন।\n\nপ্রশ্ন: {question}\nউত্তর (শুধুমাত্র ১-২ শব্দে):\"\"\"\n\n        messages = [\n            {\n                \"role\": \"user\", \n                \"content\": [\n                    {\"type\": \"image\", \"image\": image},\n                    {\"type\": \"text\", \"text\": bangla_prompt}\n                ]\n            }\n        ]\n        \n        text = processor.apply_chat_template(\n            messages, \n            tokenize=False, \n            add_generation_prompt=True\n        )\n        inputs = processor(\n            text=text, \n            images=image, \n            return_tensors=\"pt\"\n        ).to(device)\n\n        # Generate response\n        with torch.no_grad():\n            generated_ids = model.generate(\n                **inputs,\n                max_new_tokens=50, \n                do_sample=False\n            )\n        \n        # Decode\n        generated_ids = generated_ids[:, inputs['input_ids'].shape[1]:]\n        model_answer = processor.decode(\n            generated_ids[0], \n            skip_special_tokens=True\n        ).strip().split('\\n')[0] \n\n        # Fuzzy Matching\n        gt_lower = ground_truth_answer.lower()\n        pred_lower = model_answer.lower()\n        similarity_score = fuzz.partial_ratio(gt_lower, pred_lower)\n        total_similarity_score += similarity_score\n\n        is_correct = similarity_score > 85\n        if is_correct:\n            correct_predictions += 1\n            \n        # Store results\n        results.append({\n            'image_path': image_path,\n            'question': question,\n            'true_answer': ground_truth_answer,\n            'model_answer': model_answer,\n            'similarity_score': similarity_score,\n            'correct': is_correct\n        })\n\n        # Print rich output (limited)\n        if i < N_PRINT_SAMPLES:\n            print(f\"\\n--- Sample {i+1}/{N_SAMPLES} ---\")\n            # display(IPImage(filename=image_path, width=300)) # Uncomment in Jupyter\n            print(f\"Question: {question}\")\n            print(f\"True Answer: {ground_truth_answer}\")\n            print(f\"Model Answer: {model_answer}\")\n            print(f\"Score: {similarity_score}%\")\n\n    except Exception as e:\n        print(f\"\\n--- Sample {i+1}/{N_SAMPLES} ---\")\n        print(f\"SKIPPING: Error processing sample: {e}\")\n\n# --- [STEP 3/3] Final Report & Export ---\nprint(\"\\n--- [FINAL REPORT] ---\")\naccuracy = (correct_predictions / N_SAMPLES) * 100 if N_SAMPLES > 0 else 0\navg_similarity = total_similarity_score / N_SAMPLES if N_SAMPLES > 0 else 0\n\nprint(f\"Total Samples: {N_SAMPLES}\")\nprint(f\"Correct (Score > 85%): {correct_predictions}\")\nprint(f\"Accuracy: {accuracy:.2f}%\")\nprint(f\"Average Answer Similarity: {avg_similarity:.2f}%\")\n\n# 1. Save JSON\nresults_file = \"bangla_vqa_results_detailed.json\"\nwith open(results_file, 'w', encoding='utf-8') as f:\n    json.dump({\n        'accuracy': accuracy,\n        'avg_similarity': avg_similarity,\n        'correct_predictions': correct_predictions,\n        'total_samples': N_SAMPLES,\n        'detailed_results': results\n    }, f, ensure_ascii=False, indent=4)\nprint(f\"\\nDetailed JSON results saved to {results_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T09:57:07.534633Z","iopub.execute_input":"2025-12-07T09:57:07.534876Z","iopub.status.idle":"2025-12-07T10:01:56.922154Z","shell.execute_reply.started":"2025-12-07T09:57:07.534853Z","shell.execute_reply":"2025-12-07T10:01:56.921442Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n","output_type":"stream"},{"name":"stdout","text":"--- Loading Model and Processor... ---\nUsing transformers version: 5.0.0.dev0\n✓ Successfully imported Qwen2VLForConditionalGeneration\nUsing device: cuda\nLoading processor...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74bcdeb414764616bd23084f1ef9e6f9"}},"metadata":{}},{"name":"stderr","text":"The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d3b2b361af24885869909c97f46d7b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc28230192e2493889f8d7b3c543fff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"633c857eb1f74f59bac9294bad97ebd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62474d6fec6541d5b537bbca46d5208e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6196fb3f453641b79556fc8136f80854"}},"metadata":{}},{"name":"stdout","text":"✓ Processor loaded successfully\nLoading model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b59c8c74f6294c9388279ba63136e587"}},"metadata":{}},{"name":"stderr","text":"Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_section'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72cf0d20142440e6bc931d17dfe9458d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (incomplete total...): 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18231a6ca0c44274b210b83b506302c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3d5d75b9844a2bb228dbc23ec5abbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/730 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87248c0cf2cf48db995adfa4521dbf33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04bb415eb8114c06ad4fe226d1d7bd52"}},"metadata":{}},{"name":"stdout","text":"✓ Model loaded successfully.\n\n--- Loading test data and running inference... ---\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"Running inference on 150 Bangla VQA samples...\n\n--- Sample 1/150 ---\nQuestion: এই ছবিটি কিসের মাধ্যমে তোলা হয়েছে?\nTrue Answer: নেট\nModel Answer: স্টেডিয়াম থেকে\nScore: 33%\n\n--- Sample 2/150 ---\nQuestion: এই লোকটি কোন অবস্থানে খেলছে?\nTrue Answer: কলস\nModel Answer: বেসবল টেম্পলেট\nScore: 33%\n\n--- Sample 3/150 ---\nQuestion: খেলোয়াড়দের শার্টের রং কি?\nTrue Answer: কমলা\nModel Answer: রাখা হয়েছে না।\nScore: 25%\n\n--- Sample 4/150 ---\nQuestion: এই লোকটি কি একজন পেশাদার বেসবল খেলোয়াড়?\nTrue Answer: হ্যাঁ\nModel Answer: হ্যাঁ\nScore: 100%\n\n--- Sample 5/150 ---\nQuestion: তুষার কি রঙ?\nTrue Answer: সাদা\nModel Answer: সাদা\nScore: 100%\n\n--- Sample 6/150 ---\nQuestion: ব্যক্তি কি করছে?\nTrue Answer: স্কিইং\nModel Answer: স্কি করছে।\nScore: 67%\n\n--- Sample 7/150 ---\nQuestion: ব্যক্তিদের হেডওয়্যারের রঙ কী?\nTrue Answer: লাল\nModel Answer: হেডওয়্যার লাল।\nScore: 100%\n\n--- Sample 8/150 ---\nQuestion: আকাশ কি নীল?\nTrue Answer: হ্যাঁ\nModel Answer: নিশ্চিত নয়\nScore: 22%\n\n--- Sample 9/150 ---\nQuestion: পাহাড়ে কি বরফ পড়ছে?\nTrue Answer: হ্যাঁ\nModel Answer: পাহাড়ে বরফ পড়ছে।\nScore: 40%\n\n--- Sample 10/150 ---\nQuestion: সাদা ধারা কি?\nTrue Answer: contrail\nModel Answer: নেভিগেশন রেল\nScore: 0%\n\n--- [FINAL REPORT] ---\nTotal Samples: 150\nCorrect (Score > 85%): 55\nAccuracy: 36.67%\nAverage Answer Similarity: 57.60%\n\nDetailed JSON results saved to bangla_vqa_results_detailed.json\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install XlsxWriter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:56.922918Z","iopub.execute_input":"2025-12-07T10:01:56.923315Z","iopub.status.idle":"2025-12-07T10:02:00.717514Z","shell.execute_reply.started":"2025-12-07T10:01:56.923296Z","shell.execute_reply":"2025-12-07T10:02:00.716780Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting XlsxWriter\n  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\nDownloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: XlsxWriter\nSuccessfully installed XlsxWriter-3.2.9\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import xlsxwriter\n\n# Define output filename\nexcel_filename = \"bangla_vqa_results_with_images.xlsx\"\nprint(f\"Creating Excel file with embedded images: {excel_filename}...\")\n\n# Create the workbook and worksheet\nworkbook = xlsxwriter.Workbook(excel_filename)\nworksheet = workbook.add_worksheet()\n\n# Define formats\nheader_format = workbook.add_format({'bold': True, 'bg_color': '#D3D3D3', 'border': 1})\ncell_format = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})\nstatus_correct = workbook.add_format({'font_color': 'green', 'bold': True, 'border': 1, 'valign': 'top'})\nstatus_wrong = workbook.add_format({'font_color': 'red', 'bold': True, 'border': 1, 'valign': 'top'})\n\n# Set column widths\nworksheet.set_column('A:A', 20)  # Image column\nworksheet.set_column('B:B', 30)  # Question\nworksheet.set_column('C:C', 20)  # True Answer\nworksheet.set_column('D:D', 20)  # Model Answer\nworksheet.set_column('E:E', 15)  # Category (New Column)\nworksheet.set_column('F:F', 10)  # Score\nworksheet.set_column('G:G', 10)  # Correct?\n\n# Write Headers\n# Added 'Category' at index 4\nheaders = ['Image', 'Question', 'True Answer', 'Model Answer', 'Category', 'Score', 'Correct']\nfor col, header in enumerate(headers):\n    worksheet.write(0, col, header, header_format)\n\n# Write Data and Insert Images\nrow_height = 100  # Height in pixels\nworksheet.set_default_row(row_height) \n\nfor i, res in enumerate(results):\n    row = i + 1  # Start from row 1\n    \n    # 1. Insert Image (Column A)\n    image_path = res['image_path']\n    if os.path.exists(image_path):\n        try:\n            worksheet.insert_image(row, 0, image_path, {\n                'x_scale': 0.2, \n                'y_scale': 0.2, \n                'object_position': 1\n            })\n        except Exception:\n            worksheet.write(row, 0, \"Error\", cell_format)\n    else:\n        worksheet.write(row, 0, \"Not Found\", cell_format)\n\n    # 2. Write Text Data\n    worksheet.write(row, 1, res['question'], cell_format)\n    worksheet.write(row, 2, res['true_answer'], cell_format)\n    worksheet.write(row, 3, res['model_answer'], cell_format)\n    \n    # Column E: Category (BLANK)\n    worksheet.write(row, 4, \"\", cell_format)\n    \n    # Column F: Score\n    worksheet.write(row, 5, res['similarity_score'], cell_format)\n    \n    # Column G: Status\n    status = \"Correct\" if res['correct'] else \"Wrong\"\n    fmt = status_correct if res['correct'] else status_wrong\n    worksheet.write(row, 6, status, fmt)\n\nworkbook.close()\nprint(f\"✓ Success! Excel file saved as {excel_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:02:00.718717Z","iopub.execute_input":"2025-12-07T10:02:00.719023Z","iopub.status.idle":"2025-12-07T10:02:01.188729Z","shell.execute_reply.started":"2025-12-07T10:02:00.718990Z","shell.execute_reply":"2025-12-07T10:02:01.188074Z"}},"outputs":[{"name":"stdout","text":"Creating Excel file with embedded images: bangla_vqa_results_with_images.xlsx...\n✓ Success! Excel file saved as bangla_vqa_results_with_images.xlsx\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 3. Save HTML\nprint(\"Generating HTML report...\")\nhtml_output = \"\"\"\n<html>\n<head>\n    <title>Bangla VQA Test Results</title>\n    <style>\n        body { font-family: sans-serif; margin: 20px; }\n        .container { display: flex; flex-wrap: wrap; gap: 20px; }\n        .card { border: 1px solid #ccc; border-radius: 8px; padding: 15px; width: 400px; \n                box-shadow: 2px 2px 8px rgba(0,0,0,0.1); }\n        .card img { max-width: 100%; border-radius: 4px; }\n        .card p { margin: 10px 0; }\n        .correct { border-left: 5px solid green; }\n        .incorrect { border-left: 5px solid red; }\n    </style>\n</head>\n<body>\n    <h1>Bangla VQA Test Report</h1>\n    <h2>Summary</h2>\n    <p><strong>Total Samples:</strong> {N_SAMPLES}</p>\n    <p><strong>Accuracy (Score > 85%):</strong> {accuracy:.2f}%</p>\n    <p><strong>Average Similarity:</strong> {avg_similarity:.2f}%</p>\n    <hr>\n    <div class='container'>\n\"\"\"\n\ndef get_image_base64(image_path):\n    try:\n        img = Image.open(image_path)\n        buffer = BytesIO()\n        img.save(buffer, format=\"JPEG\")\n        img_b64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n        return f\"data:image/jpeg;base64,{img_b64}\"\n    except Exception:\n        return \"\"\n\n# Note: results variable is already populated from the loop above\nfor res in results:\n    img_src = get_image_base64(res['image_path'])\n    card_class = 'correct' if res['correct'] else 'incorrect'\n    \n    html_output += f\"\"\"\n    <div class='card {card_class}'>\n        <img src='{img_src}' alt='Test Image'>\n        <p><b>❓ প্রশ্ন:</b> {res['question']}</p>\n        <p><b>✅ সঠিক উত্তর:</b> {res['true_answer']}</p>\n        <p><b>🤖 মডেলের উত্তর:</b> {res['model_answer']}</p>\n        <p><b>📊 স্কোর: {res['similarity_score']}%</b></p>\n    </div>\n    \"\"\"\n\nhtml_output = html_output.replace(\"{N_SAMPLES}\", str(N_SAMPLES))\nhtml_output = html_output.replace(\"{accuracy:.2f}\", f\"{accuracy:.2f}\")\nhtml_output = html_output.replace(\"{avg_similarity:.2f}\", f\"{avg_similarity:.2f}\")\nhtml_output += \"</div></body></html>\"\n\nhtml_report_file = \"bangla_vqa_report.html\"\nwith open(html_report_file, 'w', encoding='utf-8') as f:\n    f.write(html_output)\n\nprint(f\"✓ Success! Interactive HTML report saved to {html_report_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:02:01.189431Z","iopub.execute_input":"2025-12-07T10:02:01.189688Z","iopub.status.idle":"2025-12-07T10:02:03.912009Z","shell.execute_reply.started":"2025-12-07T10:02:01.189669Z","shell.execute_reply":"2025-12-07T10:02:03.911170Z"}},"outputs":[{"name":"stdout","text":"Generating HTML report...\n✓ Success! Interactive HTML report saved to bangla_vqa_report.html\n","output_type":"stream"}],"execution_count":8}]}